{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprehensive Medical Trajectory Modeling with Interpretable Embeddings\n",
    "This notebook demonstrates a complete implementation of:\n",
    "1. Disease state embedding\n",
    "2. Interpretable transitions\n",
    "3. Trajectory analysis\n",
    "4. Visualization\n",
    "5. Synthetic data generation\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Data Structures and Medical Knowledge Base\n",
    "@dataclass\n",
    "class ClinicalConcept:\n",
    "    \"\"\"Represents a clinical concept with attributes\"\"\"\n",
    "    name: str\n",
    "    category: str\n",
    "    related_concepts: List[str]\n",
    "    temporal_profile: Dict[str, float]  # e.g., {\"acute\": 0.8, \"chronic\": 0.2}\n",
    "    severity_profile: Dict[str, float]  # e.g., {\"mild\": 0.7, \"severe\": 0.3}\n",
    "\n",
    "@dataclass\n",
    "class Disease:\n",
    "    \"\"\"Represents a disease with its attributes\"\"\"\n",
    "    name: str\n",
    "    concepts: List[ClinicalConcept]\n",
    "    common_symptoms: List[str]\n",
    "    progression_profile: Dict[str, float]\n",
    "    typical_duration: int  # in days\n",
    "\n",
    "@dataclass\n",
    "class PatientState:\n",
    "    \"\"\"Represents a patient's state at a point in time\"\"\"\n",
    "    disease_states: List[str]  # Can have multiple concurrent conditions\n",
    "    symptoms: Dict[str, float]\n",
    "    vitals: Dict[str, float]\n",
    "    lab_values: Dict[str, float]\n",
    "    timestamp: int\n",
    "\n",
    "# 2. Medical Knowledge Base Setup\n",
    "def create_medical_knowledge_base():\n",
    "    \"\"\"Create a synthetic medical knowledge base\"\"\"\n",
    "    # Clinical Concepts\n",
    "    respiratory = ClinicalConcept(\n",
    "        name=\"respiratory\",\n",
    "        category=\"system\",\n",
    "        related_concepts=[\"cough\", \"dyspnea\"],\n",
    "        temporal_profile={\"acute\": 0.6, \"chronic\": 0.4},\n",
    "        severity_profile={\"mild\": 0.7, \"moderate\": 0.2, \"severe\": 0.1}\n",
    "    )\n",
    "    \n",
    "    infectious = ClinicalConcept(\n",
    "        name=\"infectious\",\n",
    "        category=\"etiology\",\n",
    "        related_concepts=[\"fever\", \"inflammation\"],\n",
    "        temporal_profile={\"acute\": 0.8, \"chronic\": 0.2},\n",
    "        severity_profile={\"mild\": 0.6, \"moderate\": 0.3, \"severe\": 0.1}\n",
    "    )\n",
    "    \n",
    "    # Diseases\n",
    "    diseases = {\n",
    "        \"Viral Upper Respiratory Infection\": Disease(\n",
    "            name=\"Viral Upper Respiratory Infection\",\n",
    "            concepts=[respiratory, infectious],\n",
    "            common_symptoms=[\"cough\", \"fever\", \"rhinorrhea\"],\n",
    "            progression_profile={\"improvement\": 0.7, \"persistence\": 0.2, \"worsening\": 0.1},\n",
    "            typical_duration=10\n",
    "        ),\n",
    "        \"Bacterial Pneumonia\": Disease(\n",
    "            name=\"Bacterial Pneumonia\",\n",
    "            concepts=[respiratory, infectious],\n",
    "            common_symptoms=[\"cough\", \"fever\", \"dyspnea\"],\n",
    "            progression_profile={\"improvement\": 0.6, \"persistence\": 0.2, \"worsening\": 0.2},\n",
    "            typical_duration=14\n",
    "        ),\n",
    "        # Add more diseases as needed\n",
    "    }\n",
    "    \n",
    "    return diseases\n",
    "\n",
    "# 3. Synthetic Data Generation\n",
    "class SyntheticPatientGenerator:\n",
    "    def __init__(self, medical_kb: Dict[str, Disease]):\n",
    "        self.medical_kb = medical_kb\n",
    "        self.vital_ranges = {\n",
    "            \"temperature\": (36.5, 38.5),\n",
    "            \"heart_rate\": (60, 100),\n",
    "            \"respiratory_rate\": (12, 20),\n",
    "            \"blood_pressure_systolic\": (90, 140),\n",
    "            \"blood_pressure_diastolic\": (60, 90),\n",
    "            \"oxygen_saturation\": (95, 100)\n",
    "        }\n",
    "        \n",
    "    def generate_vitals(self, disease: Disease, severity: float) -> Dict[str, float]:\n",
    "        \"\"\"Generate synthetic vital signs based on disease and severity\"\"\"\n",
    "        vitals = {}\n",
    "        for vital, (low, high) in self.vital_ranges.items():\n",
    "            # Add disease-specific modifications\n",
    "            if disease.name == \"bacterial_pneumonia\" and vital == \"temperature\":\n",
    "                low += severity * 2  # Higher fever with more severe pneumonia\n",
    "            \n",
    "            vitals[vital] = np.random.uniform(low, high)\n",
    "        return vitals\n",
    "    \n",
    "    def generate_trajectory(self, \n",
    "                          initial_disease: str, \n",
    "                          duration: int,\n",
    "                          complication_prob: float = 0.1) -> List[PatientState]:\n",
    "        \"\"\"Generate a synthetic patient trajectory\"\"\"\n",
    "        trajectory = []\n",
    "        current_disease = self.medical_kb[initial_disease]\n",
    "        severity = np.random.beta(2, 5)  # Initial severity\n",
    "        \n",
    "        for t in range(duration):\n",
    "            # Generate vitals and symptoms\n",
    "            vitals = self.generate_vitals(current_disease, severity)\n",
    "            symptoms = {symptom: np.random.uniform(0.5, 1.0) \n",
    "                      for symptom in current_disease.common_symptoms}\n",
    "            \n",
    "            # Create patient state\n",
    "            state = PatientState(\n",
    "                disease_states=[current_disease.name],\n",
    "                symptoms=symptoms,\n",
    "                vitals=vitals,\n",
    "                lab_values={},  # Add if needed\n",
    "                timestamp=t\n",
    "            )\n",
    "            trajectory.append(state)\n",
    "            \n",
    "            # Update severity based on progression profile\n",
    "            prog = np.random.choice(\n",
    "                list(current_disease.progression_profile.keys()),\n",
    "                p=list(current_disease.progression_profile.values())\n",
    "            )\n",
    "            \n",
    "            if prog == \"improvement\":\n",
    "                severity *= 0.8\n",
    "            elif prog == \"worsening\":\n",
    "                severity *= 1.2\n",
    "                \n",
    "            # Possible complication\n",
    "            if np.random.random() < complication_prob:\n",
    "                # Add complication logic here\n",
    "                pass\n",
    "                \n",
    "        return trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(trajectories: List[List[PatientState]], \n",
    "                     medical_kb: Dict[str, Disease]) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Create vocabulary mappings for diseases, symptoms, and clinical concepts\n",
    "    Returns:\n",
    "        Dict with mappings for diseases, symptoms, and concepts to indices\n",
    "    \"\"\"\n",
    "    vocab = {\n",
    "        'diseases': {'<PAD>': 0},\n",
    "        'symptoms': {'<PAD>': 0},\n",
    "        'concepts': {'<PAD>': 0}\n",
    "    }\n",
    "    \n",
    "    # Collect all unique values\n",
    "    diseases = set()\n",
    "    symptoms = set()\n",
    "    concepts = set()\n",
    "    \n",
    "    # From trajectories\n",
    "    for trajectory in trajectories:\n",
    "        for state in trajectory:\n",
    "            diseases.update(state.disease_states)\n",
    "            symptoms.update(state.symptoms.keys())\n",
    "    \n",
    "    # From medical knowledge base\n",
    "    for disease in medical_kb.values():\n",
    "        diseases.add(disease.name)\n",
    "        symptoms.update(disease.common_symptoms)\n",
    "        for concept in disease.concepts:\n",
    "            concepts.add(concept.name)\n",
    "            concepts.update(concept.related_concepts)\n",
    "    \n",
    "    # Create mappings\n",
    "    for i, disease in enumerate(sorted(diseases), start=1):\n",
    "        vocab['diseases'][disease] = i\n",
    "    \n",
    "    for i, symptom in enumerate(sorted(symptoms), start=1):\n",
    "        vocab['symptoms'][symptom] = i\n",
    "        \n",
    "    for i, concept in enumerate(sorted(concepts), start=1):\n",
    "        vocab['concepts'][concept] = i\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "# Additional utility functions\n",
    "\n",
    "def save_vocabulary(vocab: Dict[str, Dict[str, int]], path: str):\n",
    "    \"\"\"Save vocabulary to file\"\"\"\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(vocab, f, indent=2)\n",
    "\n",
    "def load_vocabulary(path: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"Load vocabulary from file\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_vocabulary_sizes(vocab: Dict[str, Dict[str, int]]) -> Dict[str, int]:\n",
    "    \"\"\"Get sizes of each vocabulary\"\"\"\n",
    "    return {k: len(v) for k, v in vocab.items()}\n",
    "\n",
    "class VocabularyHandler:\n",
    "    \"\"\"Class to handle vocabulary operations\"\"\"\n",
    "    def __init__(self, vocab: Dict[str, Dict[str, int]]):\n",
    "        self.vocab = vocab\n",
    "        self.inverse_vocab = {\n",
    "            category: {idx: token for token, idx in mappings.items()}\n",
    "            for category, mappings in vocab.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, category: str, items: List[str]) -> torch.Tensor:\n",
    "        \"\"\"Encode items to indices\"\"\"\n",
    "        return torch.tensor([\n",
    "            self.vocab[category].get(item, self.vocab[category]['<PAD>'])\n",
    "            for item in items\n",
    "        ])\n",
    "    \n",
    "    def decode(self, category: str, indices: torch.Tensor) -> List[str]:\n",
    "        \"\"\"Decode indices to items\"\"\"\n",
    "        return [\n",
    "            self.inverse_vocab[category].get(idx.item(), '<PAD>')\n",
    "            for idx in indices\n",
    "        ]\n",
    "    \n",
    "    def get_size(self, category: str) -> int:\n",
    "        \"\"\"Get vocabulary size for category\"\"\"\n",
    "        return len(self.vocab[category])\n",
    "\n",
    "# # Example usage in main():\n",
    "# def main():\n",
    "#     # Create medical knowledge base\n",
    "#     medical_kb = create_medical_knowledge_base()\n",
    "    \n",
    "#     # Generate synthetic data\n",
    "#     generator = SyntheticPatientGenerator(medical_kb)\n",
    "#     trajectories = [\n",
    "#         generator.generate_trajectory(\n",
    "#             initial_disease='viral_uri',\n",
    "#             duration=random.randint(5, 15)\n",
    "#         )\n",
    "#         for _ in range(100)\n",
    "#     ]\n",
    "    \n",
    "#     # Create vocabulary\n",
    "#     vocab = create_vocabulary(trajectories, medical_kb)\n",
    "#     vocab_handler = VocabularyHandler(vocab)\n",
    "    \n",
    "#     print(\"Vocabulary sizes:\")\n",
    "#     for category, size in get_vocabulary_sizes(vocab).items():\n",
    "#         print(f\"{category}: {size} items\")\n",
    "    \n",
    "#     # Example encoding/decoding\n",
    "#     example_diseases = ['viral_uri', 'bacterial_pneumonia']\n",
    "#     encoded = vocab_handler.encode('diseases', example_diseases)\n",
    "#     decoded = vocab_handler.decode('diseases', encoded)\n",
    "#     print(\"\\nEncoding/Decoding example:\")\n",
    "#     print(f\"Original: {example_diseases}\")\n",
    "#     print(f\"Encoded: {encoded}\")\n",
    "#     print(f\"Decoded: {decoded}\")\n",
    "    \n",
    "#     # Create dataset with vocabulary handler\n",
    "#     dataset = ClinicalTrajectoryDataset(trajectories, medical_kb, vocab)\n",
    "    \n",
    "#     # Continue with the rest of the main function...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Embedding Models\n",
    "class ClinicalConceptEmbedder(nn.Module):\n",
    "    \"\"\"Embeds clinical concepts into a learned space\"\"\"\n",
    "    def __init__(self, n_concepts: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_concepts, embedding_dim)\n",
    "        self.concept_projection = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, concept_ids: torch.Tensor) -> torch.Tensor:\n",
    "        concept_embeddings = self.embedding(concept_ids)\n",
    "        return self.concept_projection(concept_embeddings)\n",
    "\n",
    "class DiseaseStateEmbedder(nn.Module):\n",
    "    \"\"\"Combines multiple elements to create a disease state embedding\"\"\"\n",
    "    def __init__(self, \n",
    "                 n_diseases: int,\n",
    "                 n_symptoms: int,\n",
    "                 n_concepts: int,\n",
    "                 embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Component embedders\n",
    "        self.disease_embedding = nn.Embedding(n_diseases, embedding_dim)\n",
    "        self.symptom_embedding = nn.Embedding(n_symptoms, embedding_dim)\n",
    "        self.concept_embedder = ClinicalConceptEmbedder(n_concepts, embedding_dim)\n",
    "        \n",
    "        # Attention mechanism for combining embeddings\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, num_heads=4)\n",
    "        \n",
    "        # Final projection\n",
    "        self.final_projection = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 3, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                disease_ids: torch.Tensor,\n",
    "                symptom_ids: torch.Tensor,\n",
    "                concept_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # Get component embeddings\n",
    "        disease_emb = self.disease_embedding(disease_ids)\n",
    "        symptom_emb = self.symptom_embedding(symptom_ids)\n",
    "        concept_emb = self.concept_embedder(concept_ids)\n",
    "        \n",
    "        # Combine using attention\n",
    "        attended_disease, _ = self.attention(\n",
    "            disease_emb.unsqueeze(0),\n",
    "            torch.cat([symptom_emb, concept_emb], dim=0),\n",
    "            torch.cat([symptom_emb, concept_emb], dim=0)\n",
    "        )\n",
    "        \n",
    "        # Concatenate and project\n",
    "        combined = torch.cat([\n",
    "            attended_disease.squeeze(0),\n",
    "            symptom_emb.mean(0).unsqueeze(0),\n",
    "            concept_emb.mean(0).unsqueeze(0)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return self.final_projection(combined)\n",
    "\n",
    "class TransitionModel(nn.Module):\n",
    "    \"\"\"Models transitions between disease states\"\"\"\n",
    "    def __init__(self, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # GRU for temporal modeling\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim,\n",
    "            num_layers=2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Transition scoring\n",
    "        self.transition_scorer = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                current_embedding: torch.Tensor,\n",
    "                history_embeddings: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        if history_embeddings is not None:\n",
    "            # Include history in transition computation\n",
    "            _, hidden = self.gru(history_embeddings)\n",
    "            hidden = hidden[-1]  # Take last layer's hidden state\n",
    "        else:\n",
    "            hidden = current_embedding\n",
    "            \n",
    "        # Predict next embedding\n",
    "        next_embedding = self.gru(current_embedding.unsqueeze(1), hidden.unsqueeze(0))\n",
    "        return next_embedding[0]\n",
    "\n",
    "class InterpretableClinicModel(nn.Module):\n",
    "    \"\"\"Complete model with interpretability layers\"\"\"\n",
    "    def __init__(self,\n",
    "                 n_diseases: int,\n",
    "                 n_symptoms: int,\n",
    "                 n_concepts: int,\n",
    "                 embedding_dim: int,\n",
    "                 n_clinical_patterns: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Core components\n",
    "        self.state_embedder = DiseaseStateEmbedder(\n",
    "            n_diseases, n_symptoms, n_concepts, embedding_dim)\n",
    "        self.transition_model = TransitionModel(embedding_dim)\n",
    "        \n",
    "        # Interpretability components\n",
    "        self.pattern_prototypes = nn.Parameter(\n",
    "            torch.randn(n_clinical_patterns, embedding_dim))\n",
    "        self.pattern_descriptions = [f\"Pattern_{i}\" for i in range(n_clinical_patterns)]\n",
    "        \n",
    "        # Decoders for interpretation\n",
    "        self.disease_decoder = nn.Linear(embedding_dim, n_diseases)\n",
    "        self.symptom_decoder = nn.Linear(embedding_dim, n_symptoms)\n",
    "        \n",
    "        # Clinical reasoning module\n",
    "        self.reasoning_templates = {\n",
    "            \"progression\": \"Disease progression suggests {}, based on {}\",\n",
    "            \"complication\": \"Possible complication of {} due to {}\",\n",
    "            \"improvement\": \"Improvement noted in {} with evidence of {}\"\n",
    "        }\n",
    "        \n",
    "    def forward(self, \n",
    "                current_state: Dict[str, torch.Tensor],\n",
    "                history: Optional[List[Dict[str, torch.Tensor]]] = None) -> Dict[str, torch.Tensor]:\n",
    "        # Embed current state\n",
    "        current_embedding = self.state_embedder(\n",
    "            current_state['disease_ids'],\n",
    "            current_state['symptom_ids'],\n",
    "            current_state['concept_ids']\n",
    "        )\n",
    "        \n",
    "        # Get history embeddings if available\n",
    "        history_embeddings = None\n",
    "        if history:\n",
    "            history_embeddings = torch.stack([\n",
    "                self.state_embedder(h['disease_ids'], \n",
    "                                  h['symptom_ids'],\n",
    "                                  h['concept_ids'])\n",
    "                for h in history\n",
    "            ])\n",
    "        \n",
    "        # Predict next state\n",
    "        next_embedding = self.transition_model(current_embedding, history_embeddings)\n",
    "        \n",
    "        # Generate interpretations\n",
    "        interpretations = self.interpret_transition(current_embedding, next_embedding)\n",
    "        \n",
    "        return {\n",
    "            'next_embedding': next_embedding,\n",
    "            'interpretations': interpretations\n",
    "        }\n",
    "        \n",
    "    def interpret_transition(self, \n",
    "                           current_embedding: torch.Tensor,\n",
    "                           next_embedding: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Compare with clinical patterns\n",
    "        pattern_similarities = F.cosine_similarity(\n",
    "            next_embedding.unsqueeze(1),\n",
    "            self.pattern_prototypes.unsqueeze(0),\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        # Decode probable diseases and symptoms\n",
    "        disease_probs = F.softmax(self.disease_decoder(next_embedding), dim=-1)\n",
    "        symptom_probs = torch.sigmoid(self.symptom_decoder(next_embedding))\n",
    "        \n",
    "        # Measure change\n",
    "        state_change = next_embedding - current_embedding\n",
    "        change_magnitude = torch.norm(state_change, dim=-1)\n",
    "        \n",
    "        return {\n",
    "            'pattern_similarities': pattern_similarities,\n",
    "            'disease_probabilities': disease_probs,\n",
    "            'symptom_probabilities': symptom_probs,\n",
    "            'change_magnitude': change_magnitude\n",
    "        }\n",
    "        \n",
    "    def generate_explanation(self, interpretations: Dict[str, torch.Tensor]) -> str:\n",
    "        \"\"\"Generate natural language explanation of transition\"\"\"\n",
    "        top_pattern_idx = interpretations['pattern_similarities'].argmax()\n",
    "        top_pattern = self.pattern_descriptions[top_pattern_idx]\n",
    "        \n",
    "        top_diseases = torch.topk(\n",
    "            interpretations['disease_probabilities'],\n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        explanation = (\n",
    "            f\"Clinical pattern most closely matches {top_pattern}. \"\n",
    "            f\"Suggesting possible progression to: {top_diseases}. \"\n",
    "            f\"Magnitude of change: {interpretations['change_magnitude']:.2f}\"\n",
    "        )\n",
    "        \n",
    "        return explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dataset and Training Infrastructure\n",
    "class ClinicalTrajectoryDataset(Dataset):\n",
    "    \"\"\"Dataset for clinical trajectories\"\"\"\n",
    "    def __init__(self, \n",
    "                 trajectories: List[List[PatientState]],\n",
    "                 medical_kb: Dict[str, Disease],\n",
    "                 vocab: Dict[str, Dict[str, int]]):\n",
    "        self.trajectories = trajectories\n",
    "        self.medical_kb = medical_kb\n",
    "        self.vocab_handler = VocabularyHandler(vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "        \n",
    "        # Convert trajectory to tensors\n",
    "        sequence = []\n",
    "        for state in trajectory:\n",
    "            # Convert state to indices using vocab handler\n",
    "            disease_ids = self.vocab_handler.encode('diseases', state.disease_states)\n",
    "            symptom_ids = self.vocab_handler.encode('symptoms', list(state.symptoms.keys()))\n",
    "            concept_ids = self.vocab_handler.encode(\n",
    "                'concepts',\n",
    "                [c.name for d in state.disease_states\n",
    "                 for c in self.medical_kb[d].concepts]\n",
    "            )\n",
    "            \n",
    "            sequence.append({\n",
    "                'disease_ids': disease_ids,\n",
    "                'symptom_ids': symptom_ids,\n",
    "                'concept_ids': concept_ids,\n",
    "                'vitals': torch.tensor(list(state.vitals.values())),\n",
    "                'timestamp': state.timestamp\n",
    "            })\n",
    "            \n",
    "        return sequence\n",
    "\n",
    "\n",
    "class TrainingEngine:\n",
    "    \"\"\"Handles model training and validation\"\"\"\n",
    "    def __init__(self,\n",
    "                 model: InterpretableClinicModel,\n",
    "                 train_loader: DataLoader,\n",
    "                 val_loader: DataLoader,\n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(model.parameters())\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=5)\n",
    "        \n",
    "        # Loss functions\n",
    "        self.transition_loss = nn.MSELoss()\n",
    "        self.classification_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.train_metrics = []\n",
    "        self.val_metrics = []\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        epoch_metrics = defaultdict(list)\n",
    "        \n",
    "        for batch in tqdm(self.train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss = 0\n",
    "            \n",
    "            # Process each trajectory in batch\n",
    "            for trajectory in batch:\n",
    "                trajectory = [\n",
    "                    {k: torch.Tensor(v).to(self.device) for k, v in state.items()}\n",
    "                    for state in trajectory\n",
    "                ]\n",
    "                \n",
    "                # Forward pass through sequence\n",
    "                for t in range(len(trajectory) - 1):\n",
    "                    current_state = trajectory[t]\n",
    "                    next_state = trajectory[t + 1]\n",
    "                    history = trajectory[:t] if t > 0 else None\n",
    "                    \n",
    "                    print(current_state)\n",
    "                    output = self.model(current_state, history)\n",
    "                    \n",
    "                    # Compute losses\n",
    "                    next_embedding = self.model.state_embedder(\n",
    "                        next_state['disease_ids'],\n",
    "                        next_state['symptom_ids'],\n",
    "                        next_state['concept_ids']\n",
    "                    )\n",
    "                    \n",
    "                    transition_loss = self.transition_loss(\n",
    "                        output['next_embedding'],\n",
    "                        next_embedding\n",
    "                    )\n",
    "                    \n",
    "                    disease_loss = self.classification_loss(\n",
    "                        output['interpretations']['disease_probabilities'],\n",
    "                        next_state['disease_ids']\n",
    "                    )\n",
    "                    \n",
    "                    total_loss += transition_loss + disease_loss\n",
    "                    \n",
    "                    # Track metrics\n",
    "                    epoch_metrics['transition_loss'].append(transition_loss.item())\n",
    "                    epoch_metrics['disease_loss'].append(disease_loss.item())\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        return {k: np.mean(v) for k, v in epoch_metrics.items()}\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_metrics = defaultdict(list)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                # Similar to train_epoch but without backward pass\n",
    "                pass\n",
    "                \n",
    "        return {k: np.mean(v) for k, v in val_metrics.items()}\n",
    "    \n",
    "    def train(self, n_epochs: int):\n",
    "        for epoch in range(n_epochs):\n",
    "            train_metrics = self.train_epoch()\n",
    "            val_metrics = self.validate()\n",
    "            \n",
    "            self.train_metrics.append(train_metrics)\n",
    "            self.val_metrics.append(val_metrics)\n",
    "            \n",
    "            self.scheduler.step(val_metrics['total_loss'])\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "            print(f\"Train metrics: {train_metrics}\")\n",
    "            print(f\"Val metrics: {val_metrics}\")\n",
    "\n",
    "# 6. Visualization Tools\n",
    "class TrajectoryVisualizer:\n",
    "    \"\"\"Tools for visualizing clinical trajectories\"\"\"\n",
    "    def __init__(self, model: InterpretableClinicModel):\n",
    "        self.model = model\n",
    "        self.umap_transform = umap.UMAP(n_components=2)\n",
    "        self.tsne_transform = TSNE(n_components=2)\n",
    "        \n",
    "    def plot_embedding_space(self, \n",
    "                           embeddings: torch.Tensor,\n",
    "                           labels: List[str],\n",
    "                           method: str = 'umap'):\n",
    "        \"\"\"Plot embeddings in 2D space\"\"\"\n",
    "        # Transform embeddings to 2D\n",
    "        transform = self.umap_transform if method == 'umap' else self.tsne_transform\n",
    "        embeddings_2d = transform.fit_transform(embeddings.detach().cpu().numpy())\n",
    "        \n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        scatter = plt.scatter(\n",
    "            embeddings_2d[:, 0],\n",
    "            embeddings_2d[:, 1],\n",
    "            c=np.arange(len(embeddings_2d)),\n",
    "            cmap='viridis'\n",
    "        )\n",
    "        \n",
    "        # Add labels\n",
    "        for i, label in enumerate(labels):\n",
    "            plt.annotate(\n",
    "                label,\n",
    "                (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "            \n",
    "        plt.colorbar(scatter)\n",
    "        plt.title(f'Disease State Embeddings ({method.upper()})')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_trajectory(self, \n",
    "                       trajectory: List[PatientState],\n",
    "                       with_interpretations: bool = True):\n",
    "        \"\"\"Plot patient trajectory with interpretations\"\"\"\n",
    "        # Create trajectory graph\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges\n",
    "        for i in range(len(trajectory) - 1):\n",
    "            current_state = trajectory[i]\n",
    "            next_state = trajectory[i + 1]\n",
    "            \n",
    "            # Add nodes\n",
    "            G.add_node(i, state=current_state)\n",
    "            G.add_node(i + 1, state=next_state)\n",
    "            \n",
    "            # Add edge\n",
    "            if with_interpretations:\n",
    "                # Get model interpretation\n",
    "                current_tensor = self._state_to_tensor(current_state)\n",
    "                interpretation = self.model.interpret_transition(\n",
    "                    current_tensor,\n",
    "                    self._state_to_tensor(next_state)\n",
    "                )\n",
    "                G.add_edge(i, i + 1, interpretation=interpretation)\n",
    "            else:\n",
    "                G.add_edge(i, i + 1)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        pos = nx.spring_layout(G)\n",
    "        nx.draw(\n",
    "            G, pos,\n",
    "            with_labels=True,\n",
    "            node_color='lightblue',\n",
    "            node_size=1000,\n",
    "            arrowsize=20\n",
    "        )\n",
    "        \n",
    "        if with_interpretations:\n",
    "            edge_labels = {\n",
    "                (i, i + 1): self.model.generate_explanation(G.edges[i, i + 1]['interpretation'])\n",
    "                for i in range(len(trajectory) - 1)\n",
    "            }\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "            \n",
    "        plt.title('Patient Trajectory Graph')\n",
    "        plt.show()\n",
    "        \n",
    "    def _state_to_tensor(self, state: PatientState) -> torch.Tensor:\n",
    "        \"\"\"Convert PatientState to tensor for model input\"\"\"\n",
    "        # Implementation depends on specific state representation\n",
    "        pass\n",
    "\n",
    "# 7. Analysis Tools\n",
    "class TrajectoryAnalyzer:\n",
    "    \"\"\"Tools for analyzing clinical trajectories\"\"\"\n",
    "    def __init__(self, model: InterpretableClinicModel, medical_kb: Dict[str, Disease]):\n",
    "        self.model = model\n",
    "        self.medical_kb = medical_kb\n",
    "        \n",
    "    def analyze_transition_patterns(self, \n",
    "                                  trajectories: List[List[PatientState]]) -> pd.DataFrame:\n",
    "        \"\"\"Analyze common transition patterns in trajectories\"\"\"\n",
    "        patterns = []\n",
    "        \n",
    "        for trajectory in trajectories:\n",
    "            for i in range(len(trajectory) - 1):\n",
    "                current_state = trajectory[i]\n",
    "                next_state = trajectory[i + 1]\n",
    "                \n",
    "                # Get model interpretation\n",
    "                output = self.model(\n",
    "                    self._state_to_tensor(current_state),\n",
    "                    history=[self._state_to_tensor(s) for s in trajectory[:i]]\n",
    "                )\n",
    "                \n",
    "                patterns.append({\n",
    "                    'from_state': current_state.disease_states,\n",
    "                    'to_state': next_state.disease_states,\n",
    "                    'change_magnitude': output['interpretations']['change_magnitude'].item(),\n",
    "                    'top_pattern': self.model.pattern_descriptions[\n",
    "                        output['interpretations']['pattern_similarities'].argmax().item()\n",
    "                    ]\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(patterns)\n",
    "    \n",
    "    def identify_critical_transitions(self,\n",
    "                                   trajectory: List[PatientState],\n",
    "                                   threshold: float = 0.8) -> List[int]:\n",
    "        \"\"\"Identify critical transition points in trajectory\"\"\"\n",
    "        critical_points = []\n",
    "        \n",
    "        for i in range(len(trajectory) - 1):\n",
    "            current_state = trajectory[i]\n",
    "            next_state = trajectory[i + 1]\n",
    "            \n",
    "            output = self.model(self._state_to_tensor(current_state))\n",
    "            \n",
    "            # Check if transition is critical based on change magnitude\n",
    "            if output['interpretations']['change_magnitude'].item() > threshold:\n",
    "                critical_points.append(i)\n",
    "                \n",
    "        return critical_points\n",
    "    \n",
    "    def generate_counterfactuals(self,\n",
    "                               trajectory: List[PatientState],\n",
    "                               n_alternatives: int = 3) -> List[List[PatientState]]:\n",
    "        \"\"\"Generate counterfactual trajectories\"\"\"\n",
    "        counterfactuals = []\n",
    "        \n",
    "        # Implementation would depend on specific counterfactual generation strategy\n",
    "        return counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disease_ids': tensor([2]), 'symptom_ids': tensor([1, 3, 4]), 'concept_ids': tensor([6, 4]), 'vitals': tensor([ 37.8337,  61.2573,  14.8813, 102.8987,  66.7386,  95.8988]), 'timestamp': tensor([])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "For batched (3-D) `query`, expected `key` and `value` to be 3-D but found 2-D and 2-D tensors respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainingEngine(model, train_loader, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n\u001b[1;32m     39\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m TrajectoryVisualizer(model)\n",
      "Cell \u001b[0;32mIn[40], line 132\u001b[0m, in \u001b[0;36mTrainingEngine.train\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_epochs: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m--> 132\u001b[0m         train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mappend(train_metrics)\n",
      "Cell \u001b[0;32mIn[40], line 87\u001b[0m, in \u001b[0;36mTrainingEngine.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m history \u001b[38;5;241m=\u001b[39m trajectory[:t] \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(current_state)\n\u001b[0;32m---> 87\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[1;32m     90\u001b[0m next_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_embedder(\n\u001b[1;32m     91\u001b[0m     next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisease_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     92\u001b[0m     next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymptom_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     93\u001b[0m     next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     94\u001b[0m )\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 134\u001b[0m, in \u001b[0;36mInterpretableClinicModel.forward\u001b[0;34m(self, current_state, history)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    131\u001b[0m             current_state: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    132\u001b[0m             history: Optional[List[Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Embed current state\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     current_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_embedder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisease_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msymptom_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconcept_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Get history embeddings if available\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     history_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 48\u001b[0m, in \u001b[0;36mDiseaseStateEmbedder.forward\u001b[0;34m(self, disease_ids, symptom_ids, concept_ids)\u001b[0m\n\u001b[1;32m     45\u001b[0m concept_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept_embedder(concept_ids)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Combine using attention\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m attended_disease, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisease_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msymptom_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msymptom_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Concatenate and project\u001b[39;00m\n\u001b[1;32m     55\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     56\u001b[0m     attended_disease\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     57\u001b[0m     symptom_emb\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     58\u001b[0m     concept_emb\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/modules/activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1343\u001b[0m         query,\n\u001b[1;32m   1344\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/functional.py:6014\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[1;32m   5984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   5985\u001b[0m         multi_head_attention_forward,\n\u001b[1;32m   5986\u001b[0m         tens_ops,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6011\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   6012\u001b[0m     )\n\u001b[0;32m-> 6014\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[43m_mha_shape_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\n\u001b[1;32m   6016\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6018\u001b[0m \u001b[38;5;66;03m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[1;32m   6019\u001b[0m \u001b[38;5;66;03m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[1;32m   6020\u001b[0m \u001b[38;5;66;03m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n\u001b[1;32m   6021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   6022\u001b[0m     \u001b[38;5;66;03m# unsqueeze if the input is unbatched\u001b[39;00m\n",
      "File \u001b[0;32m~/vds/.venv/lib/python3.11/site-packages/torch/nn/functional.py:5786\u001b[0m, in \u001b[0;36m_mha_shape_check\u001b[0;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[1;32m   5783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   5784\u001b[0m     \u001b[38;5;66;03m# Batched Inputs\u001b[39;00m\n\u001b[1;32m   5785\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 5786\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m key\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, (\n\u001b[1;32m   5787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched (3-D) `query`, expected `key` and `value` to be 3-D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5788\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensors respectively\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5789\u001b[0m     )\n\u001b[1;32m   5790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5791\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m key_padding_mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[1;32m   5792\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched (3-D) `query`, expected `key_padding_mask` to be `None` or 2-D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5793\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey_padding_mask\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5794\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: For batched (3-D) `query`, expected `key` and `value` to be 3-D but found 2-D and 2-D tensors respectively"
     ]
    }
   ],
   "source": [
    "\n",
    "medical_kb = create_medical_knowledge_base()\n",
    "\n",
    "# Generate synthetic data\n",
    "generator = SyntheticPatientGenerator(medical_kb)\n",
    "trajectories = [\n",
    "    generator.generate_trajectory(\n",
    "        initial_disease='Viral Upper Respiratory Infection',\n",
    "        duration=random.randint(5, 15)\n",
    "    )\n",
    "    for _ in range(100)\n",
    "]\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = create_vocabulary(trajectories, medical_kb)\n",
    "\n",
    "# Create dataset\n",
    "dataset = ClinicalTrajectoryDataset(trajectories, medical_kb, vocab)\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: x  # Custom collate function for variable length sequences\n",
    "    )\n",
    "    \n",
    "# Initialize model\n",
    "model = InterpretableClinicModel(\n",
    "    n_diseases=len(vocab['diseases']),\n",
    "    n_symptoms=len(vocab['symptoms']),\n",
    "    n_concepts=len(vocab['concepts']),\n",
    "    embedding_dim=64,\n",
    "    n_clinical_patterns=10\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer = TrainingEngine(model, train_loader, None)\n",
    "trainer.train(n_epochs=10)\n",
    "\n",
    "# Visualize results\n",
    "visualizer = TrajectoryVisualizer(model)\n",
    "analyzer = TrajectoryAnalyzer(model, medical_kb)\n",
    "\n",
    "# Example trajectory analysis\n",
    "trajectory = trajectories[0]\n",
    "visualizer.plot_trajectory(trajectory, with_interpretations=True)\n",
    "\n",
    "# Analyze patterns\n",
    "patterns_df = analyzer.analyze_transition_patterns(trajectories)\n",
    "print(\"\\nCommon Transition Patterns:\")\n",
    "print(patterns_df.head())\n",
    "\n",
    "# Identify critical points\n",
    "critical_points = analyzer.identify_critical_transitions(trajectory)\n",
    "print(\"\\nCritical Transition Points:\", critical_points)\n",
    "\n",
    "# Generate and visualize counterfactuals\n",
    "counterfactuals = analyzer.generate_counterfactuals(trajectory)\n",
    "for i, cf_trajectory in enumerate(counterfactuals):\n",
    "    print(f\"\\nCounterfactual Trajectory {i + 1}:\")\n",
    "    visualizer.plot_trajectory(cf_trajectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
